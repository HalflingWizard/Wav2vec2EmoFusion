{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Iqi_jAjJTQD"
      },
      "source": [
        "# 🚀 Install, Import, and Log In"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2la1s_6HJjf"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v_hr9jhHMU1",
        "outputId": "0cb034cc-6292-48ae-e05e-1b65182d1aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.0/499.0 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m555.3/555.3 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q speechbrain --upgrade -qqq\n",
        "!pip install wandb --upgrade -qqq\n",
        "!pip install torchmetrics --upgrade -qqq\n",
        "!pip install torchinfo --upgrade -qqq\n",
        "!pip install onnx --upgrade -qqq\n",
        "!pip install transformers -qqq\n",
        "!pip install einops --upgrade -qqq\n",
        "!pip install nlpaug --upgrade -qqq\n",
        "!pip install pytorch-metric-learning --upgrade -qqq\n",
        "!pip install git+https://github.com/huggingface/accelerate -qqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCiM2wnCJmOK"
      },
      "source": [
        "## Weights and Biases login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC35lijVHUqt",
        "outputId": "1a4978fe-6109-49ab-c987-7e617bf2a3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login() # Log in with your wandb creditentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoabZ7sStuW8"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuQI4M91tf1J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "from torchinfo import summary\n",
        "\n",
        "import torchaudio\n",
        "import nlpaug.augmenter.audio as naa\n",
        "import nlpaug.flow as naf\n",
        "\n",
        "from speechbrain.nnet.losses import AdditiveAngularMargin, LogSoftmaxWrapper\n",
        "from speechbrain.lobes.models.ECAPA_TDNN import AttentiveStatisticsPooling\n",
        "\n",
        "from pytorch_metric_learning import losses, samplers\n",
        "\n",
        "import onnx\n",
        "from onnx import shape_inference\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from einops import rearrange\n",
        "\n",
        "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "\n",
        "from accelerate import Accelerator\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkDPDFgUOckn"
      },
      "source": [
        "## Set-up better GPU stack trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2QPb2uyOdUr"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-blQEzkoFFY1"
      },
      "source": [
        "## Ensure deterministic behavior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVL0mIS9FDRx"
      },
      "outputs": [],
      "source": [
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvzQ5kNOzzYF"
      },
      "source": [
        "## Set up GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjviwq78z1Jt"
      },
      "outputs": [],
      "source": [
        "accelerator = Accelerator(mixed_precision = 'fp16')\n",
        "device = accelerator.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMazsAf6J81k"
      },
      "source": [
        "# 👩‍🔬 Define the Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UexlatABOlRp"
      },
      "source": [
        "## Sweep Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVkDld6pOimg"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid'\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pw-UBRtoEAy"
      },
      "source": [
        "## Sweep Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN0oLDAvPBQM"
      },
      "outputs": [],
      "source": [
        "parameters_dict = {\n",
        "    'fold': {\n",
        "        # 'values': [('01','02'), ('03','04'), ('05','06'), ('07','08'), ('09','10'), ('11','12'), ('13','14'), ('15','16'), ('17','18'), ('19','20'), ('21','22'), ('23','24')] # RAVDESS\n",
        "        'values': [[\"03\"], [\"08\"], [\"09\"], [\"10\"], [\"11\"], [\"12\"], [\"13\"], [\"14\"], [\"15\"], [\"16\"]]\n",
        "    }\n",
        "  }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVBzY0pLpHHQ"
      },
      "source": [
        "## Training General Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xro74JIGpMqC"
      },
      "outputs": [],
      "source": [
        "parameters_dict.update({\n",
        "    'epochs':{\n",
        "      'value': 20\n",
        "    },\n",
        "    'batch_size':{\n",
        "        'value': 32\n",
        "    },\n",
        "    'learning_rate':{\n",
        "        'value': 5e-3\n",
        "    },\n",
        "    'weight_decay':{\n",
        "        'value': 9e-3\n",
        "    },\n",
        "    'warmup_steps':{\n",
        "        'value': 10\n",
        "    },\n",
        "    'num_cycles':{\n",
        "        'value': 1\n",
        "    },\n",
        "    'loss':{\n",
        "        'value': 'AF'\n",
        "    },\n",
        "    'optimizer':{\n",
        "        'value': 'AdamW'\n",
        "    },\n",
        "    'alpha':{\n",
        "        'value': 0.5\n",
        "    },\n",
        "    'beta':{\n",
        "        'value': 1\n",
        "    },\n",
        "    'temporal_average':{\n",
        "        'value': 'asp'\n",
        "    },\n",
        "    'scale':{\n",
        "        'value': 1\n",
        "    },\n",
        "    'margin':{\n",
        "        'value': 0.2\n",
        "    },\n",
        "    'layer_selection':{\n",
        "        'value': 'asp'\n",
        "    },\n",
        "    'layer_attn_dim':{\n",
        "        'value': 32\n",
        "    },\n",
        "    'time_attn_dim':{\n",
        "        'value': 256\n",
        "    },\n",
        "    'emo_emdb_ratio':{\n",
        "        'value': 0.5\n",
        "    },\n",
        "    'hidden_size':{\n",
        "        'value': 64\n",
        "    },\n",
        "    'gater_attn_dim':{\n",
        "        'value': 12\n",
        "    }\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTyc78OIuMV8"
      },
      "source": [
        "## Speech Features Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOM1ZNjOuPsm"
      },
      "outputs": [],
      "source": [
        "parameters_dict.update({\n",
        "    'max_length':{\n",
        "        'value': 350\n",
        "    },\n",
        "    'sample_rate':{\n",
        "        'value': 16000\n",
        "    },\n",
        "    'aug_prob':{\n",
        "        'value': 0.0\n",
        "    },\n",
        "    'proj_drop':{\n",
        "        'value': 0.2\n",
        "    },\n",
        "    'attn_drop':{\n",
        "        'value': 0.0\n",
        "    }\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBKL4uMZpWiB"
      },
      "source": [
        "## Model Specific Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viMclRJb98Kf"
      },
      "outputs": [],
      "source": [
        "parameters_dict.update({\n",
        "    'input_size':{\n",
        "        'value': (12, 350, 768)\n",
        "    },\n",
        "    'embeddings':{\n",
        "        'value': 768\n",
        "    },\n",
        "    'num_heads':{\n",
        "        'value': 2\n",
        "    }\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eynOxEhpoa2B"
      },
      "source": [
        "## Dataset and input Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ard4-CxgoeuB"
      },
      "outputs": [],
      "source": [
        "parameters_dict.update({\n",
        "    'dataset':{\n",
        "        'value':\"EMODB\"\n",
        "    },\n",
        "    'path':{\n",
        "        'value':'kntu-asp-dl/EMODB/EMODB:wav2vec_fp16_noft_base'\n",
        "    },\n",
        "    'layers':{\n",
        "        'value': list(range(1,13))\n",
        "    },\n",
        "    'classes':{\n",
        "        'value': 7\n",
        "    },\n",
        "    'class_names':{\n",
        "        'value':['anger', 'anxiety/fear', 'boredom', 'disgust', 'happiness', 'neutral', 'sadness']\n",
        "    },\n",
        "    'input_channels':{\n",
        "        'value': 1\n",
        "    }\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF7z2gP4oHaS"
      },
      "source": [
        "## Metadata about the run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD0J6xZRoTn6"
      },
      "outputs": [],
      "source": [
        "parameters_dict.update({\n",
        "    'project_name':{\n",
        "        'value':\"Thesis\"\n",
        "    }\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktd3_4lPaoiZ"
      },
      "source": [
        "# 🧹 Initialize the Sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-slr8i-S5aJ",
        "outputId": "370c9a62-0ba5-4207-a7a2-8273b86d240c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is sweep_id? (leave out if this is first sweep) \n",
            "Create sweep with ID: m4dhq01a\n",
            "Sweep URL: https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a\n"
          ]
        }
      ],
      "source": [
        "save_model = False\n",
        "sweep_id = input('What is sweep_id? (leave out if this is first sweep) ')\n",
        "if sweep_id==\"\":\n",
        "    sweep_id = wandb.sweep(sweep_config, project=parameters_dict['project_name']['value'])\n",
        "    save_model = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zqvq1fCnyPD"
      },
      "source": [
        "# 🚰 Constructing the Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTnN4fPzaoiZ"
      },
      "source": [
        "## Define pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyG1K8cDaoia"
      },
      "outputs": [],
      "source": [
        "def model_pipeline(hyperparameters=None):\n",
        "\n",
        "    # tell wandb to get started\n",
        "    with wandb.init(config=hyperparameters):\n",
        "\n",
        "      # access all HPs through wandb.config, so logging matches execution!\n",
        "      config = wandb.config\n",
        "\n",
        "      # download dataset\n",
        "      paths = []\n",
        "      for i in config.layers:\n",
        "        dataset = wandb.use_artifact(config.path+f'_t{i}', type='dataset')\n",
        "        # dataset path\n",
        "        path = dataset.download()\n",
        "        paths.append(path)\n",
        "\n",
        "      # make the model, data, and optimization problem\n",
        "      model, best_model, train_loader, test_loader, criterion, optimizer, scheduler = make(config, paths)\n",
        "      try:\n",
        "        print(summary(model, (config.batch_size, config.input_size[0], config.input_size[1], config.input_size[2])))\n",
        "      except:\n",
        "        print('⚠️ Something is wrong with TorchInfo.')\n",
        "\n",
        "      # and use them to train the model\n",
        "      train(model, train_loader, test_loader, criterion, optimizer, scheduler, config)\n",
        "\n",
        "      # load the best model from training\n",
        "      best_model.load_state_dict(torch.load('model.pkl'))\n",
        "\n",
        "      # and test its final performance\n",
        "      test(best_model, test_loader, criterion, config)\n",
        "\n",
        "      pickle_artifact = wandb.Artifact(\n",
        "          name = f'Model.pkl',\n",
        "          type=\"model\",\n",
        "          metadata=dict(config))\n",
        "\n",
        "      wandb.save(\"model.pkl\")\n",
        "      pickle_artifact.add_file(\"model.pkl\")\n",
        "      wandb.log_artifact(pickle_artifact)\n",
        "\n",
        "\n",
        "      if save_model == True:\n",
        "        try:\n",
        "          # Save the model in the exchangeable ONNX format\n",
        "          onnx_artifact = wandb.Artifact(\n",
        "              name = f'Model.onnx',\n",
        "              type=\"model\",\n",
        "              metadata=dict(config))\n",
        "\n",
        "          # Params for ONNX\n",
        "          dummy_input = torch.randn(config.batch_size, config.input_size, device = device).to(torch.float16)\n",
        "          input_names = [ \"input\" ]\n",
        "          output_names = [ \"output\" ]\n",
        "\n",
        "          # export model as ONNX file\n",
        "          torch.onnx.export(best_model,\n",
        "                            dummy_input,\n",
        "                            \"pytorch_model.onnx\",\n",
        "                            verbose=False,\n",
        "                            input_names=input_names,\n",
        "                            output_names=output_names,\n",
        "                            export_params=True,\n",
        "                            dynamic_axes={'input' : {0 : 'batch_size'},\n",
        "                                          'output' : {0 : 'batch_size'}})\n",
        "          onnx.save(onnx.shape_inference.infer_shapes(onnx.load(\"pytorch_model.onnx\")), \"model.onnx\")\n",
        "\n",
        "          wandb.save(\"model.onnx\")\n",
        "\n",
        "          onnx_artifact.add_file(\"model.onnx\")\n",
        "\n",
        "          wandb.log_artifact(onnx_artifact)\n",
        "        except:\n",
        "          print(\"⚠️ Couldn't save the model.\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvCxNvYU2qJ4"
      },
      "source": [
        "## Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NISGwudr2pgZ"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha = 0.8, gamma = 2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        sig = nn.Sigmoid()\n",
        "        inputs = sig(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        #first compute binary cross-entropy\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        BCE_EXP = torch.exp(-BCE)\n",
        "        focal_loss = self.alpha * (1-BCE_EXP)**self.gamma * BCE\n",
        "\n",
        "        return focal_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlYzOu0gRD7y"
      },
      "outputs": [],
      "source": [
        "class DaviesBouldin(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DaviesBouldin, self).__init__()\n",
        "\n",
        "    def pytorch_euclidean(self, a, b):\n",
        "        return torch.sqrt(torch.sum((a-b)**2))\n",
        "\n",
        "    def forward(self, X, labels):\n",
        "\n",
        "        n_cluster = len(torch.bincount(labels.int()))\n",
        "        cluster_k = [X[labels == k] for k in range(n_cluster)]\n",
        "        centroids = [torch.mean(k, dim = 0) for k in cluster_k]\n",
        "        variances = [torch.mean(torch.Tensor([self.pytorch_euclidean(p, centroids[i]) for p in k])) for i, k in enumerate(cluster_k)]\n",
        "        db = []\n",
        "\n",
        "        for i in range(n_cluster):\n",
        "            for j in range(n_cluster):\n",
        "                if j != i:\n",
        "                    db.append((variances[i] + variances[j]) / self.pytorch_euclidean(centroids[i], centroids[j]))\n",
        "        if n_cluster == 1:\n",
        "          db.append(0)\n",
        "\n",
        "        return(max(db) / n_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_I49aUHAKKiP"
      },
      "outputs": [],
      "source": [
        "class CenterLoss(nn.Module):\n",
        "    \"\"\"Center loss.\n",
        "\n",
        "    Reference:\n",
        "    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int): number of classes.\n",
        "        feat_dim (int): feature dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10, feat_dim=2, use_gpu=True):\n",
        "        super(CenterLoss, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.feat_dim = feat_dim\n",
        "        self.use_gpu = use_gpu\n",
        "\n",
        "        if self.use_gpu:\n",
        "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
        "        else:\n",
        "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: feature matrix with shape (batch_size, feat_dim).\n",
        "            labels: ground truth labels with shape (batch_size).\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
        "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
        "        distmat.addmm_(x, self.centers.t(), beta=1, alpha=-2)\n",
        "\n",
        "        classes = torch.arange(self.num_classes).long()\n",
        "        if self.use_gpu: classes = classes.cuda()\n",
        "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
        "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
        "\n",
        "        dist = distmat * mask.float()\n",
        "        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjWJT91n7cUs"
      },
      "outputs": [],
      "source": [
        "class RingLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Refer to paper\n",
        "    Ring loss: Convex Feature Normalization for Face Recognition\n",
        "    \"\"\"\n",
        "    def __init__(self, type='L2', loss_weight=1.0):\n",
        "        super(RingLoss, self).__init__()\n",
        "        self.radius = nn.Parameter(torch.Tensor(1)).cuda()\n",
        "        self.radius.data.fill_(-1)\n",
        "        self.loss_weight = loss_weight\n",
        "        self.type = type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.pow(2).sum(dim=1).pow(0.5)\n",
        "        if self.radius.data[0] < 0: # Initialize the radius with the mean feature norm of first iteration\n",
        "            self.radius.data.fill_(x.mean().item())\n",
        "        if self.type == 'L1': # Smooth L1 Loss\n",
        "            loss1 = F.smooth_l1_loss(x, self.radius.expand_as(x)).mul_(self.loss_weight)\n",
        "            loss2 = F.smooth_l1_loss(self.radius.expand_as(x), x).mul_(self.loss_weight)\n",
        "            ringloss = loss1 + loss2\n",
        "        elif self.type == 'auto': # Divide the L2 Loss by the feature's own norm\n",
        "            diff = x.sub(self.radius.expand_as(x)) / (x.mean().detach().clamp(min=0.5))\n",
        "            diff_sq = torch.pow(torch.abs(diff), 2).mean()\n",
        "            ringloss = diff_sq.mul_(self.loss_weight)\n",
        "        else: # L2 Loss, if not specified\n",
        "            diff = x.sub(self.radius.expand_as(x))\n",
        "            diff_sq = torch.pow(torch.abs(diff), 2).mean()\n",
        "            ringloss = diff_sq.mul_(self.loss_weight)\n",
        "        return ringloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udNcFzWY4EGP"
      },
      "outputs": [],
      "source": [
        "class CrossEntropy(nn.Module):\n",
        "    def __init__(self, num_classes = 4, feat_dim = 768):\n",
        "        super(CrossEntropy, self).__init__()\n",
        "        self.CELoss = nn.CrossEntropyLoss()\n",
        "        self.RingLoss = RingLoss()\n",
        "\n",
        "    def forward(self, inputs, embeddings, targets):\n",
        "\n",
        "        return self.CELoss(inputs, targets) + self.RingLoss(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssy2xTCnvTse"
      },
      "outputs": [],
      "source": [
        "class AFLoss(nn.Module):\n",
        "    def __init__(self, margin, scale, num_layers):\n",
        "        super().__init__()\n",
        "        self.AAMLoss = LogSoftmaxWrapper(AdditiveAngularMargin(margin = margin, scale=scale))\n",
        "\n",
        "    def forward(self, inputs, gate_weights, targets):\n",
        "        targets, ses_sex_emo = targets\n",
        "        labels = process_labels(targets, self.AAMLoss)\n",
        "        gate_weights = gate_weights.sum(dim=0)\n",
        "        loss = self.AAMLoss(inputs, labels) + (gate_weights.std()/gate_weights.mean())**2\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUURyymWaoia"
      },
      "source": [
        "## Define `make`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20EC9FZGaoia"
      },
      "outputs": [],
      "source": [
        "def make(config,  paths):\n",
        "    # Make the data\n",
        "    train, test =  get_data(config,  paths, train=True), get_data(config,  paths, train=False)\n",
        "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
        "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
        "\n",
        "    # Make the model\n",
        "    model = Model(config)\n",
        "\n",
        "    # Make best model\n",
        "    best_model = Model(config)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = get_loss(config.loss, config)\n",
        "    params = list(model.parameters()) + list(criterion.parameters())\n",
        "\n",
        "    optimizer = torch.optim.AdamW(params,\n",
        "                                  lr = config.learning_rate,\n",
        "                                  weight_decay = config.weight_decay)\n",
        "\n",
        "    # Make the scheduler\n",
        "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer,\n",
        "                                                                   num_warmup_steps = config.warmup_steps,\n",
        "                                                                   num_training_steps = config.epochs,\n",
        "                                                                   num_cycles = config.num_cycles)\n",
        "\n",
        "    model, best_model, optimizer, train_loader, test_loader = accelerator.prepare(model, best_model, optimizer, train_loader, test_loader)\n",
        "\n",
        "    return model, best_model, train_loader, test_loader, criterion, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt-w26881oux"
      },
      "outputs": [],
      "source": [
        "def get_loss(loss_function, config):\n",
        "  if loss_function.startswith('CE'):\n",
        "    loss = CrossEntropy(config.classes, config.embeddings)\n",
        "  elif loss_function.startswith(\"MM\"):\n",
        "    loss = nn.MultiMarginLoss()\n",
        "  elif loss_function.startswith(\"MLSM\"):\n",
        "    loss = nn.MultiLabelSoftMarginLoss()\n",
        "  elif loss_function.startswith(\"FL\"):\n",
        "    loss = FocalLoss(alpha=0.75, gamma = 2)\n",
        "  elif loss_function.startswith(\"BCE\"):\n",
        "    loss = nn.BCEWithLogitsLoss()\n",
        "  elif loss_function.startswith(\"AF\"):\n",
        "    loss = AFLoss(margin = config.margin, scale=config.scale, num_layers=len(config.layers))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ5bbKTBMmFF"
      },
      "source": [
        "# 🔊 Speech Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkMn9HuKnSub"
      },
      "source": [
        "## Reading wav file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HdCJ_I7MqUb"
      },
      "outputs": [],
      "source": [
        "def get_waveform(file_path, sample_rate):\n",
        "  wf, sr = torchaudio.load(file_path)\n",
        "  resample = torchaudio.transforms.Resample(sr, sample_rate)\n",
        "  waveform = resample(wf)\n",
        "  return waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xClzeKHPos32"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNCZAg9totoA"
      },
      "outputs": [],
      "source": [
        "def augment(waveform, aug_prob, sample_rate):\n",
        "\n",
        "  aug = naf.Sometimes([\n",
        "    naa.SpeedAug(factor=(0.8, 1.2)),\n",
        "    naa.LoudnessAug(),\n",
        "    naa.VtlpAug(sample_rate)\n",
        "    ],\n",
        "    aug_p = aug_prob)\n",
        "\n",
        "  waveform = waveform.numpy()\n",
        "  waveform = waveform.reshape(-1)\n",
        "  waveform = aug.augment(waveform)\n",
        "  waveform = torch.from_numpy(waveform)\n",
        "  return torch.unsqueeze(waveform, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN_ampWvnf2o"
      },
      "source": [
        "## Tile waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTMYtMsxNQ-l"
      },
      "outputs": [],
      "source": [
        "def tile(waveform, expected_time):\n",
        "  waveform_time = waveform.shape[1]\n",
        "  expected_time = expected_time\n",
        "  repeat_times = (expected_time // waveform_time) + 1\n",
        "  tiled_data = waveform.repeat(1, repeat_times)\n",
        "  return tiled_data[:, :expected_time]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Llwj01ppOe8"
      },
      "source": [
        "## Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypArLytopQUH"
      },
      "outputs": [],
      "source": [
        "def standardize(waveform):\n",
        "  means = waveform.mean()\n",
        "  stds = waveform.std()\n",
        "  waveform = (waveform - means) / (stds + 1e-7)\n",
        "  return waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALWLzatbKI5p"
      },
      "source": [
        "# 📡 Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwpxxOKX0_AX"
      },
      "source": [
        "## Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7xC5XEGkKMD"
      },
      "outputs": [],
      "source": [
        "class get_data(Dataset):\n",
        "  def __init__(self, config,  paths, train):\n",
        "    self.speaker_out = [f\"{int(x):02}\" for x in config.fold]\n",
        "    self.train = train\n",
        "\n",
        "    self.paths =  paths\n",
        "    self.files = self.filter_files(self.paths[0])\n",
        "\n",
        "    self.length = config.max_length\n",
        "    self.sample_rate = config.sample_rate\n",
        "\n",
        "    self.labels_list = [self.get_label(file_name)[1] for file_name in self.files]\n",
        "    self.num_classes = len(set(self.labels_list))\n",
        "    self.majority_count = max([sum([item==label for item in self.labels_list]) for label in set(self.labels_list)])\n",
        "\n",
        "    self.aug_prob = config.aug_prob\n",
        "\n",
        "  def filter_files(self, path):\n",
        "    list_of_files = os.listdir(path)\n",
        "    if not self.train:\n",
        "      file_list = [item[:-3] for item in list_of_files if item.startswith(self.speaker_out[0])]\n",
        "      return file_list\n",
        "    elif self.train:\n",
        "      file_list = [item[:-3] for item in list_of_files if not(item.startswith(self.speaker_out[0]))]\n",
        "      return file_list\n",
        "\n",
        "  def get_wav(self, file):\n",
        "    waveform = get_waveform(file, self.sample_rate)\n",
        "    if waveform.shape[0] > 1:\n",
        "      waveform = torch.mean(waveform, dim=0).unsqueeze(0)\n",
        "    if self.train:\n",
        "      waveform = augment(waveform, self.aug_prob, self.sample_rate)\n",
        "    tiled_wav = tile(waveform, self.length)\n",
        "    std_wav = standardize(tiled_wav)\n",
        "    return std_wav\n",
        "\n",
        "  def get_features(self, path, durations):\n",
        "    short_x = torch.load(path)\n",
        "    x = []\n",
        "    for f_i, d_i in zip(short_x, durations):\n",
        "      x += [float(f_i)] * int(d_i)\n",
        "    x = torch.FloatTensor(x)\n",
        "    x = torch.unsqueeze(x, 0)\n",
        "    x = standardize(x)\n",
        "    x = tile(x, self.length)\n",
        "    return x\n",
        "\n",
        "  def get_label(self, file_name):\n",
        "    emo_dict = {\n",
        "    'W':0, # anger\n",
        "    'A':1, # anxiety/fear\n",
        "    'L':2, # boredom\n",
        "    'E':3, # disgust\n",
        "    'F':4, # happiness\n",
        "    'T':5, # sadness\n",
        "    'N':6, # neutral\n",
        "    }\n",
        "\n",
        "    gender_dict = {\n",
        "      '03': 0,\n",
        "      '08': 1,\n",
        "      '09': 1,\n",
        "      '10': 0,\n",
        "      '11': 0,\n",
        "      '12': 0,\n",
        "      '13': 1,\n",
        "      '14': 1,\n",
        "      '15': 0,\n",
        "      '16': 1\n",
        "    }\n",
        "    # emotion_char = file_name[6:8] #RAVDESS\n",
        "    emotion_char = file_name[5] # EMODB\n",
        "    # emotion_char = file_name[19] #IEMOCAP\n",
        "    # session_char = file_name[4]\n",
        "    # gender_char = file_name[15]\n",
        "    fold_char = file_name[:2]\n",
        "    label = int(int(fold_char) * 100 + int(gender_dict[fold_char]) * 10 + emo_dict[emotion_char])\n",
        "    return (emo_dict[emotion_char], label)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    file_name = self.files[index]\n",
        "\n",
        "    features = []\n",
        "\n",
        "    for path in self.paths:\n",
        "      file_path = os.path.join(path, file_name + '.pt')\n",
        "      e = torch.load(file_path)\n",
        "      e = torch.squeeze(e)\n",
        "      e = rearrange(e, \"l c -> c l\")\n",
        "      e = tile(e, self.length)\n",
        "      e = rearrange(e, \"c l -> l c\")\n",
        "      features.append(e)\n",
        "\n",
        "    features = torch.stack(features, dim=0)\n",
        "\n",
        "    label = self.get_label(file_name)\n",
        "    return features, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW7sm5jT1Bxd"
      },
      "outputs": [],
      "source": [
        "def make_loader(dataset, batch_size):\n",
        "  if dataset.train:\n",
        "    sampler = samplers.MPerClassSampler(labels=dataset.labels_list, m=(batch_size//dataset.num_classes)+1, batch_size=batch_size, length_before_new_iter=dataset.majority_count*dataset.num_classes)\n",
        "    loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         sampler = sampler)\n",
        "  else:\n",
        "    loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=batch_size)\n",
        "  return loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbqFdFCnxWXU"
      },
      "source": [
        "# 🏗️ Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSBtNH4m62Si"
      },
      "source": [
        "## Attentive Stats Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57J7dbDR65zt"
      },
      "outputs": [],
      "source": [
        "class ASP(nn.Module):\n",
        "\n",
        "    def __init__(self, num_emdb, attn_dim=None):\n",
        "        super().__init__()\n",
        "        self.num_emdb = num_emdb\n",
        "        if not attn_dim:\n",
        "          attn_dim = num_emdb\n",
        "        self.asp = AttentiveStatisticsPooling(channels=num_emdb, attention_channels=attn_dim, global_context=True)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "\n",
        "        x = rearrange(x, \"b l c -> b c l\")\n",
        "        x = self.asp(x)\n",
        "        x = x.squeeze()\n",
        "\n",
        "        x, _ = torch.split(x, self.num_emdb, dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYa5fZ3exKUN"
      },
      "source": [
        "## Maxout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO6CKd4yxLmL"
      },
      "outputs": [],
      "source": [
        "class Maxout(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, pool_size):\n",
        "        super().__init__()\n",
        "        self.d_in, self.d_out, self.pool_size = d_in, d_out, pool_size\n",
        "        self.lin = nn.Linear(d_in, d_out * pool_size)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        shape = list(inputs.size())\n",
        "        shape[-1] = self.d_out\n",
        "        shape.append(self.pool_size)\n",
        "        max_dim = len(shape) - 1\n",
        "        out = self.lin(inputs)\n",
        "        m, i = out.view(*shape).max(max_dim)\n",
        "        return m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8FCrLf0jcAo"
      },
      "source": [
        "## Classification Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RzDxpn2jekl"
      },
      "outputs": [],
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "\n",
        "    def __init__(self, num_emdb, num_class, p=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm = nn.LayerNorm(normalized_shape = num_emdb)\n",
        "        self.dropout = nn.Dropout(p=p)\n",
        "        self.head = nn.Linear(num_emdb, num_class)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.head(self.dropout(self.norm(x)))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expert"
      ],
      "metadata": {
        "id": "4x1ZmMm7Fxdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Expert(nn.Module):\n",
        "\n",
        "    def __init__(self, embeddings, attn_dim, hidden_size, num_class, p=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.asp = ASP(num_emdb = embeddings, attn_dim=attn_dim)\n",
        "        self.maxout = Maxout(d_in = embeddings, d_out = hidden_size, pool_size = 3)\n",
        "        self.head = ClassificationHead(num_emdb= hidden_size, num_class= num_class, p= p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.maxout(self.asp(x))\n",
        "        e = x.clone()\n",
        "        x = self.head(x)\n",
        "        return x, e"
      ],
      "metadata": {
        "id": "rlof7WV5F0xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gater"
      ],
      "metadata": {
        "id": "JAzftOwqHGVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Gater(nn.Module):\n",
        "\n",
        "    def __init__(self, num_experts, attn_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.asp = ASP(num_emdb = num_experts, attn_dim=attn_dim)\n",
        "        self.sm = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x, e):\n",
        "\n",
        "        temp_x = x.clone().detach()\n",
        "\n",
        "        # GATER:BEGIN\n",
        "        e = rearrange(e, \"b l c -> b c l\")\n",
        "        w = self.asp(e)\n",
        "        w = self.sm(w).unsqueeze(2)\n",
        "        x = (x*w)\n",
        "        #GATER:END\n",
        "\n",
        "        temp_o = x.clone().detach()\n",
        "        self.weights = (temp_o/temp_x).mean(dim=-1)\n",
        "\n",
        "        return x.sum(dim=1), w"
      ],
      "metadata": {
        "id": "S-7k7aIgHHs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgipQhHLqKWM"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jcq_qspkgHim"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.experts = nn.ModuleList([\n",
        "                                    nn.Sequential(\n",
        "                                        Expert(\n",
        "                                            embeddings= config.embeddings,\n",
        "                                            attn_dim= config.time_attn_dim,\n",
        "                                            hidden_size= config.hidden_size,\n",
        "                                            num_class= config.classes,\n",
        "                                            p= config.proj_drop\n",
        "                                          )\n",
        "                                    )\n",
        "                                    for _ in range(len(config.layers))\n",
        "                                    ]\n",
        "                                  )\n",
        "\n",
        "        self.gater = Gater(num_experts = len(config.layers),\n",
        "                           attn_dim = config.gater_attn_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, extra_logs=False):\n",
        "\n",
        "        expert_logits = []\n",
        "        expert_embeddings = []\n",
        "        for i, expert in enumerate(self.experts):\n",
        "          l, e = expert(x[:,i])\n",
        "          expert_logits.append(l)\n",
        "          expert_embeddings.append(e)\n",
        "        x = torch.stack(expert_logits, dim=1)\n",
        "        e = torch.stack(expert_embeddings, dim=1)\n",
        "\n",
        "        output, w = self.gater(x, e)\n",
        "\n",
        "        return x, output, w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUvR194wKrQq"
      },
      "source": [
        "# 👟 Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "935OAzMWoaB6"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, dev_loader, criterion, optimizer, scheduler, config):\n",
        "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=1)\n",
        "\n",
        "    best_acc   = 0.0\n",
        "\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "\n",
        "      train_loss = []\n",
        "      train_acc  = []\n",
        "      dev_loss   = []\n",
        "      dev_acc    = []\n",
        "\n",
        "      for inputs, labels in train_loader:\n",
        "          loss, accuracy = train_batch(inputs, labels, model, optimizer, criterion, config)\n",
        "          train_loss.append(loss.item())\n",
        "          train_acc.append(accuracy.item())\n",
        "\n",
        "      for inputs, labels in dev_loader:\n",
        "\n",
        "          loss, accuracy = dev_batch(inputs, labels, model, criterion, config)\n",
        "          dev_loss.append(loss.item())\n",
        "          dev_acc.append(accuracy.item())\n",
        "\n",
        "      scheduler.step()\n",
        "\n",
        "      # Report metrics every epoch\n",
        "      wandb.log({\n",
        "            \"Train loss\": np.mean(train_loss),\n",
        "            \"Train Accuracy\": np.mean(train_acc),\n",
        "            \"Validation loss\": np.mean(dev_loss),\n",
        "            \"Validation Accuracy\": np.mean(dev_acc)\n",
        "            },\n",
        "          step=epoch)\n",
        "\n",
        "      # Keep best model\n",
        "      new_acc = np.mean(dev_acc)\n",
        "      if new_acc > best_acc:\n",
        "        best_acc = max(best_acc, new_acc)\n",
        "        torch.save(model.state_dict(), 'model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGaH8QC7qtlL"
      },
      "outputs": [],
      "source": [
        "def train_batch(inputs, labels, model, optimizer, criterion, config):\n",
        "\n",
        "    model = model.train()\n",
        "\n",
        "    # ensuring that the model is in train mode.\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass ➡\n",
        "    _, outputs, gate_weights = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    targets = process_labels(labels, criterion)\n",
        "    loss = criterion(outputs, gate_weights, targets)\n",
        "\n",
        "    # Backward pass ⬅\n",
        "    optimizer.zero_grad()\n",
        "    accelerator.backward(loss)\n",
        "\n",
        "    # Step with optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    y_true = labels[0].tolist()\n",
        "    y_pred = predicted.tolist()\n",
        "    UA = Accuracy(task = 'multiclass',\n",
        "                  num_classes = config.classes,\n",
        "                  average = 'macro')\n",
        "    accuracy = UA(torch.tensor(y_pred), torch.tensor(y_true))\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft6vbEBdz1yU"
      },
      "outputs": [],
      "source": [
        "def dev_batch(inputs, labels, model, criterion, config):\n",
        "    model = model.train()\n",
        "\n",
        "    # ensuring that the model is in inference mode.\n",
        "    model.eval()\n",
        "\n",
        "    # Forward pass ➡\n",
        "    _, outputs, gate_weights = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    targets = process_labels(labels, criterion)\n",
        "    loss = criterion(outputs, gate_weights, targets)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    y_true = labels[0].tolist()\n",
        "    y_pred = predicted.tolist()\n",
        "    UA = Accuracy(task = 'multiclass',\n",
        "                  num_classes = config.classes,\n",
        "                  average = 'macro')\n",
        "    accuracy = UA(torch.tensor(y_pred), torch.tensor(y_true))\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jo3y-aK56Lpo"
      },
      "outputs": [],
      "source": [
        "def process_labels(labels, criterion):\n",
        "  targets = labels\n",
        "  if str(criterion) in ['MultiLabelSoftMarginLoss()', 'FocalLoss()', 'BCEWithLogitsLoss()', 'AdditiveAngularMargin()']:\n",
        "    enc = OneHotEncoder()\n",
        "    enc.fit(np.array([0,1,2,3,4,5,6]).reshape(-1, 1))\n",
        "    cpu_labels = labels.cpu()\n",
        "    targets = torch.tensor(enc.transform(cpu_labels.reshape(-1, 1)).todense(), dtype=torch.float, device = device)\n",
        "  elif str(criterion) in ['LogSoftmaxWrapper(\\n  (loss_fn): AdditiveAngularMargin()\\n  (criterion): KLDivLoss()\\n)']:\n",
        "    targets = targets.unsqueeze(1)\n",
        "  return targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAA7DW7u8mnQ"
      },
      "source": [
        "# 🧪 Test and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9ewMS5l0xAS"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion, config):\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "  expert_predictions = []\n",
        "  weights = []\n",
        "\n",
        "  # ensuring that the model is in inference mode.\n",
        "  model = model.train()\n",
        "  model.eval()\n",
        "\n",
        "  # Run the model on some test examples\n",
        "  for inputs, labels in test_loader:\n",
        "      votes, outputs, _ = model(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      y_true += labels[0].tolist()\n",
        "      y_pred += predicted.tolist()\n",
        "      expert_predictions += votes.argmax(dim=2).tolist()\n",
        "  weights += model.gater.weights.squeeze().tolist()\n",
        "\n",
        "  # weighted and unweighted accuracy\n",
        "  WA = Accuracy(task = 'multiclass',\n",
        "                num_classes = config.classes,\n",
        "                average = 'micro')\n",
        "  UA = Accuracy(task = 'multiclass',\n",
        "                num_classes = config.classes,\n",
        "                average = 'macro')\n",
        "\n",
        "  # selected layers table\n",
        "\n",
        "  my_data = [a + b + [c, d] for (a,b), (c,d) in list(zip(zip(expert_predictions, weights), zip(y_pred, y_true)))]\n",
        "  columns=[f'expert #{i+1} predictions' for i in range(len(config.layers))]+[f'expert #{i+1} weight' for i in range(len(config.layers))]+['prediction', 'target']\n",
        "\n",
        "\n",
        "  wandb.log({\n",
        "      \"Weighted Accuracy\": WA(torch.tensor(y_pred), torch.tensor(y_true)),\n",
        "      \"Unweighted Accuracy\": UA(torch.tensor(y_pred), torch.tensor(y_true)),\n",
        "      \"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
        "                    y_true=y_true, preds=y_pred,\n",
        "                    class_names=config.class_names),\n",
        "      \"Votes and Weights\": wandb.Table(data=my_data, columns=columns)\n",
        "      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRQLHHoqqzPm"
      },
      "outputs": [],
      "source": [
        "def readable_targets(labels):\n",
        "  emo_dict = {\n",
        "      0:'anger',\n",
        "      1:'anxiety/fear',\n",
        "      2:'boredom',\n",
        "      3:'disgust',\n",
        "      4:'happiness',\n",
        "      5:'sadness',\n",
        "      6:'neutral',\n",
        "  }\n",
        "  str_labels = [emo_dict[x] for x in labels]\n",
        "\n",
        "  return str_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTBT0qub4gpt"
      },
      "source": [
        "# 🏃‍♀️ Run training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aft9a4W4jOf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ddd10816-9ca7-44df-ce40-8482627cc362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t77622m5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattn_drop: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \taug_prob: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_names: ['anger', 'anxiety/fear', 'boredom', 'disgust', 'happiness', 'neutral', 'sadness']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclasses: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: EMODB\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembeddings: 768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \temo_emdb_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfold: ['03']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgater_attn_dim: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_channels: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: [12, 350, 768]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_attn_dim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_selection: asp\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: AF\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmargin: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_length: 350\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cycles: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpath: kntu-asp-dl/EMODB/EMODB:wav2vec_fp16_noft_base\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tproj_drop: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tproject_name: Thesis\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_average: asp\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_attn_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.009\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhalflingwizard\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230224_094859-t77622m5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/halflingwizard/Thesis/runs/t77622m5' target=\"_blank\">glorious-sweep-1</a></strong> to <a href='https://wandb.ai/halflingwizard/Thesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/halflingwizard/Thesis' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/halflingwizard/Thesis/runs/t77622m5' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis/runs/t77622m5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t1, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t2, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:20.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t3, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t4, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:20.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t5, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t6, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t7, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:20.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t8, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t9, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t10, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t11, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t12, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:21.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================================================\n",
            "Layer (type:depth-idx)                                       Output Shape              Param #\n",
            "==============================================================================================================\n",
            "Model                                                        [32, 12, 7]               --\n",
            "├─ModuleList: 1-1                                            --                        --\n",
            "│    └─Sequential: 2-1                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-1                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-2                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-2                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-3                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-3                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-4                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-4                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-5                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-5                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-6                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-6                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-7                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-7                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-8                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-8                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-9                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-9                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-10                                      [32, 7]                   --\n",
            "│    │    └─Expert: 3-10                                     [32, 7]                   936,199\n",
            "│    └─Sequential: 2-11                                      [32, 7]                   --\n",
            "│    │    └─Expert: 3-11                                     [32, 7]                   936,199\n",
            "│    └─Sequential: 2-12                                      [32, 7]                   --\n",
            "│    │    └─Expert: 3-12                                     [32, 7]                   936,199\n",
            "├─Gater: 1-2                                                 [32, 7]                   --\n",
            "│    └─ASP: 2-13                                             [32, 12]                  --\n",
            "│    │    └─AttentiveStatisticsPooling: 3-13                 [32, 24, 1]               624\n",
            "│    └─Softmax: 2-14                                         [32, 12]                  --\n",
            "==============================================================================================================\n",
            "Total params: 11,235,012\n",
            "Trainable params: 11,235,012\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 105.89\n",
            "==============================================================================================================\n",
            "Input size (MB): 412.88\n",
            "Forward/backward pass size (MB): 688.93\n",
            "Params size (MB): 44.94\n",
            "Estimated Total Size (MB): 1146.74\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [14:30<00:00, 43.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Couldn't save the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁▇██████████████████</td></tr><tr><td>Train loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Unweighted Accuracy</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁████▇██████████████</td></tr><tr><td>Validation loss</td><td>█▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Weighted Accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>0.99539</td></tr><tr><td>Train loss</td><td>0.60347</td></tr><tr><td>Unweighted Accuracy</td><td>0.95918</td></tr><tr><td>Validation Accuracy</td><td>0.86429</td></tr><tr><td>Validation loss</td><td>0.77642</td></tr><tr><td>Weighted Accuracy</td><td>0.95918</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glorious-sweep-1</strong> at: <a href='https://wandb.ai/halflingwizard/Thesis/runs/t77622m5' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis/runs/t77622m5</a><br/>Synced 5 W&B file(s), 2 media file(s), 5 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230224_094859-t77622m5/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j7dbqhuu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattn_drop: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \taug_prob: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_names: ['anger', 'anxiety/fear', 'boredom', 'disgust', 'happiness', 'neutral', 'sadness']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclasses: 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: EMODB\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembeddings: 768\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \temo_emdb_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfold: ['12']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tgater_attn_dim: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_channels: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_size: [12, 350, 768]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_attn_dim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_selection: asp\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: AF\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmargin: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_length: 350\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_cycles: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: AdamW\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tpath: kntu-asp-dl/EMODB/EMODB:wav2vec_fp16_noft_base\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tproj_drop: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tproject_name: Thesis\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tsample_rate: 16000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscale: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttemporal_average: asp\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttime_attn_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.009\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230224_100857-j7dbqhuu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/halflingwizard/Thesis/runs/j7dbqhuu' target=\"_blank\">polar-sweep-6</a></strong> to <a href='https://wandb.ai/halflingwizard/Thesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/halflingwizard/Thesis' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis/sweeps/m4dhq01a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/halflingwizard/Thesis/runs/j7dbqhuu' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis/runs/j7dbqhuu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t1, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t2, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t3, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t4, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t5, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t6, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t7, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t8, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t9, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t10, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t11, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact EMODB:wav2vec_fp16_noft_base_t12, 108.71MB. 535 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   535 of 535 files downloaded.  \n",
            "Done. 0:0:0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================================================\n",
            "Layer (type:depth-idx)                                       Output Shape              Param #\n",
            "==============================================================================================================\n",
            "Model                                                        [32, 12, 7]               --\n",
            "├─ModuleList: 1-1                                            --                        --\n",
            "│    └─Sequential: 2-1                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-1                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-2                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-2                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-3                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-3                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-4                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-4                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-5                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-5                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-6                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-6                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-7                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-7                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-8                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-8                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-9                                       [32, 7]                   --\n",
            "│    │    └─Expert: 3-9                                      [32, 7]                   936,199\n",
            "│    └─Sequential: 2-10                                      [32, 7]                   --\n",
            "│    │    └─Expert: 3-10                                     [32, 7]                   936,199\n",
            "│    └─Sequential: 2-11                                      [32, 7]                   --\n",
            "│    │    └─Expert: 3-11                                     [32, 7]                   936,199\n",
            "│    └─Sequential: 2-12                                      [32, 7]                   --\n",
            "│    │    └─Expert: 3-12                                     [32, 7]                   936,199\n",
            "├─Gater: 1-2                                                 [32, 7]                   --\n",
            "│    └─ASP: 2-13                                             [32, 12]                  --\n",
            "│    │    └─AttentiveStatisticsPooling: 3-13                 [32, 24, 1]               624\n",
            "│    └─Softmax: 2-14                                         [32, 12]                  --\n",
            "==============================================================================================================\n",
            "Total params: 11,235,012\n",
            "Trainable params: 11,235,012\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 105.89\n",
            "==============================================================================================================\n",
            "Input size (MB): 412.88\n",
            "Forward/backward pass size (MB): 688.93\n",
            "Params size (MB): 44.94\n",
            "Estimated Total Size (MB): 1146.74\n",
            "==============================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [14:18<00:00, 42.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Couldn't save the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁▆██████████████████</td></tr><tr><td>Train loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Unweighted Accuracy</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁▇█▇█▇██████████████</td></tr><tr><td>Validation loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Weighted Accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>1.0</td></tr><tr><td>Train loss</td><td>0.60347</td></tr><tr><td>Unweighted Accuracy</td><td>1.0</td></tr><tr><td>Validation Accuracy</td><td>0.64286</td></tr><tr><td>Validation loss</td><td>0.62643</td></tr><tr><td>Weighted Accuracy</td><td>1.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">polar-sweep-6</strong> at: <a href='https://wandb.ai/halflingwizard/Thesis/runs/j7dbqhuu' target=\"_blank\">https://wandb.ai/halflingwizard/Thesis/runs/j7dbqhuu</a><br/>Synced 5 W&B file(s), 2 media file(s), 5 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230224_100857-j7dbqhuu/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
          ]
        }
      ],
      "source": [
        "# Build, train and analyze the model with the pipeline\n",
        "wandb.agent(sweep_id,project=parameters_dict['project_name']['value'],entity='halflingwizard',function=model_pipeline)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}